id: "lts-mismatch-render-manual-hints"
seed_message: |
  "I'm hitting critical issues with our Learnosity integration and we launch in 4 days. Our custom drag-and-drop questions aren't validating properly after we upgraded to 2025.1 LTS—the validation callback just never fires. Worked fine in 2024.2. And our progress tracking is completely unreliable—the progress bar jumps around randomly and we're hammering our backend with hundreds of requests per minute. I've been debugging this for 6 hours and I'm getting nowhere. I need solutions, not 'check the documentation' responses. This is make-or-break for our company."

milestones:
  - id: M1_goal
    description: Clarifies user's actual goal/outcome
    intents_any: [ "ask_for_goal" ]
    score_effect:
      communication: 1.75
      discovery: 1.0

  - id: M1_goal
    description: Clarifies Learnosity implementation details
    intents_any: [ "confirm_learnosity_implementation_details" ]
    score_effect:
      communication: 1.5
      evidence: 1.0
  - id: M2_logs
    description: Requests HAR/network logs or reproduction details
    intents_any: [ "ask_for_diagnostic_data", "ask_for_repro" ]
    score_effect:
      communication: 2.0
      reasoning: 1.0
      evidence: 1.0
  - id: M3_context
    description: Gathers device/OS/app/webview/file-type details
    intents_any: [ "ask_for_context" ]
    score_effect:
      communication: +1.5'
  - id: M4_solution
    description: Proposes plausible resolution path
    intents_any: [ "propose_fix" ]

rubric:
  weights:
    discovery: 0.25 # M1 + M3
    evidence: 0.25 # M2
    reasoning: 0.30 # M4 quality
    communication: 0.20
  pass_threshold: 0.72
determinism:
  temperature: 0.2
  top_p: 0.9
  style: "You are a stressed but cooperative developer working on implementing a digital assessment. Keep answers short. Do not reveal solution unless asked the right things. In the event the user missing the point, tactfully steer them back on track."
