# Database Configuration
# SQLite (default - simple file-based database)
DATABASE_URL=sqlite:///./data/data.db
# PostgreSQL (for production)
# DATABASE_URL=postgresql+psycopg://username:password@localhost:5432/database_name

# LLM Provider Configuration
MODEL_PROVIDER=anthropic
# Available providers: openai, anthropic, ollama
MODEL_NAME=
# Leave MODEL_NAME empty for provider defaults
LLM_REQUEST_TIMEOUT=30
MAX_OUTPUT_TOKENS=512

# API Keys (required based on MODEL_PROVIDER)
OPENAI_API_KEY="your_openai_api_key_here"
ANTHROPIC_API_KEY="your_anthropic_api_key_here"
HUGGINGFACE_TOKEN="your_huggingface_token_here"

# Ollama Configuration (if using ollama provider)
OLLAMA_BASE_URL=http://localhost:11434

# Rate Limiting Configuration
DEFAULT_RATE_LIMIT=60          # requests per window
DEFAULT_RATE_WINDOW=60         # window in seconds
CHAT_RATE_LIMIT=30            # chat endpoint specific limit
CHAT_RATE_WINDOW=60
SESSION_RATE_LIMIT=10         # session creation limit
SESSION_RATE_WINDOW=60
FINISH_RATE_LIMIT=10          # session finish limit
FINISH_RATE_WINDOW=60

# Security Configuration
ALLOWED_ORIGINS=http://localhost:3000,https://yourdomain.com
API_KEY_REQUIRED=false        # Set to true to require API key authentication

# Logging Configuration
LOG_LEVEL=INFO                # DEBUG|INFO|WARNING|ERROR
STRUCTURED_LOGGING=true       # Enable structured JSON logging

# Cache Configuration
EMBEDDING_CACHE_SIZE=1000     # Max embeddings to cache in memory
EMBEDDING_CACHE_DIR=.cache/embeddings

# Application Configuration
SCENARIO_FILE=scenario.yml    # Path to scenario configuration
DEBUG=false                   # Enable debug mode